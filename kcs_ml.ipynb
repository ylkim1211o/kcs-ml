{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnpWPEhSC5nw"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "from sklearn.model_selection import KFold\n",
        "from lightgbm import LGBMClassifier\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "plt.rcParams['font.family'] = 'NanumBarunGothic'\n",
        "\n",
        "#데이터를 불러온다.\n",
        "df_all_real = pd.read_excel('/gdrive/MyDrive/data_science/train.xlsx')\n",
        "df_all_test = pd.read_excel('/gdrive/MyDrive/data_science/test.xlsx')\n",
        " \n",
        "df_all = copy.deepcopy(df_all_real)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvKoV-FYHICZ"
      },
      "source": [
        "#데이터 전처리#\n",
        "#필요없는 데이터 삭제\n",
        "\n",
        "del df_all['검사결과코드']\n",
        "# del df_all['핵심적발']\n",
        "# del df_all['우범여부']\n",
        "del df_all['신고일자']\n",
        "del df_all['신고번호']\n",
        "del df_all['수입자부호']\n",
        "del df_all['신고인부호']\n",
        "del df_all['과세가격원화금액']\n",
        "del df_all['관세율']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwAC8zP6HRPw"
      },
      "source": [
        "#데이터 전처리#\n",
        "#결측값 제거\n",
        "df_all.fillna('others',inplace=True)\n",
        "\n",
        "#연속형 데이터 log scale로 변경\n",
        "numeric_columns = ['신고중량(KG)']\n",
        "\n",
        "for col in numeric_columns:\n",
        "    df_all[col] = df_all[col].apply(lambda x: np.log1p(x))\n",
        "\n",
        "#신고중량을 구간별로 나누어 준다.\n",
        "group_list = list(range(0,11,1))\n",
        "labeling = ['group'+str(x+1) for x in group_list]\n",
        "df_all['신고중량(KG)'] = pd.cut(df_all['신고중량(KG)'],group_list,right=False,labels=labeling[:-1])\n",
        "df_all['신고중량(KG)'] = df_all['신고중량(KG)'].astype('str')\n",
        "df_all['신고중량(KG)'].fillna('others',inplace=True)\n",
        "\n",
        "#HS10단위부호 집합의 크기를 줄여준다.\n",
        "df_all['HS10단위부호'] = df_all['HS10단위부호'].astype('str')\n",
        "df_all['HS10단위부호'] = df_all['HS10단위부호'].str[0:2]+df_all['HS10단위부호'].str[6:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf6LNUNlHjnY"
      },
      "source": [
        "#데이터 전처리#\n",
        "#feature 전부를 category 사용 위해 타입 변경\n",
        "\n",
        "col_list = ['통관지세관부호', '해외거래처부호', '특송업체부호', '수입통관계획코드', '수입신고구분코드', '수입거래구분코드',\n",
        "       '수입종류코드', '징수형태코드', '신고중량(KG)', '운송수단유형코드', '반입보세구역부호', 'HS10단위부호','관세율구분코드',\n",
        "       '적출국가코드', '원산지국가코드']\n",
        "\n",
        "for col in col_list:\n",
        "    df_all[col] = df_all[col].astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICgJ5prit0I1"
      },
      "source": [
        "#1 stage autoencoder 학습, 테스트 데이터 생성\n",
        "\n",
        "#1 stage에서는 우범(1)을 제외한 정상(0),핵심우범(2) 에대해서 분류만을 하기 때문에\n",
        "#학습시 우범(1) 에대한 데이터는 삭제해주고 핵심우범 숫자 (2) -> (1) 로 변경해준다. \n",
        "df_all_auto = copy.deepcopy(df_all)\n",
        "\n",
        "del df_all_auto['우범여부']\n",
        "\n",
        "df_all_auto = df_all_auto[df_all_auto['핵심적발'] != 1]\n",
        "df_all_auto.loc[(df_all_auto['핵심적발'] == 2),'핵심적발'] = 1\n",
        "\n",
        "#mean 인코더가 오버피팅 가능성이 있어서 일부의 데이터로 인코더를 학습함\n",
        "\n",
        "import category_encoders as ce\n",
        "\n",
        "df_train, df_test = train_test_split(df_all_auto,test_size=0.3,random_state=13)\n",
        "\n",
        "ce_model = ce.target_encoder.TargetEncoder(cols=col_list)\n",
        "ce_model.fit(df_train[col_list],df_train.iloc[:,-1])\n",
        "\n",
        "#mean 인코더 학습후 autoencorder 학습 때는 정상데이터가 많을수록 좋다 판단. \n",
        "#데이터 다시 스플릿 후 mean 인코딩\n",
        " \n",
        "df_train, df_test = train_test_split(df_all_auto,test_size=0.1,random_state=13)\n",
        "\n",
        "df_train[col_list] = ce_model.transform(df_train[col_list])\n",
        "\n",
        "df_test[col_list] = ce_model.transform(df_test[col_list])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63K9FdR4xAMn"
      },
      "source": [
        "#autoencorder 학습을위해 정상데이터만 분류\n",
        "x_train = copy.deepcopy(df_train)\n",
        "x_train = x_train[x_train['핵심적발'] == 0]\n",
        "x_train = x_train.iloc[:,:-1]\n",
        "\n",
        "x_test = copy.deepcopy(df_test)\n",
        "x_test = x_test[x_test['핵심적발'] == 0]\n",
        "x_test = x_test.iloc[:,:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1sdFnwpuD0Q"
      },
      "source": [
        "#autoencorder 계층 생성\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense \n",
        "from tensorflow.keras import Model,Input,regularizers\n",
        "\n",
        "leaky_relu = tf.nn.leaky_relu\n",
        "\n",
        "input_dim = x_train.shape[1]\n",
        "encoding_dim = 20\n",
        "\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "\n",
        "encoder = Dense(encoding_dim, activation=leaky_relu, )(input_layer)\n",
        "\n",
        "latent_layer = Dense(25, activation=leaky_relu)(encoder)\n",
        "\n",
        "decoder = Dense(encoding_dim, activation=leaky_relu)(latent_layer)\n",
        "\n",
        "output = Dense(input_dim, activation=leaky_relu)(decoder)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz1l5axuxW32"
      },
      "source": [
        "#epoch, batch, optimizer, 손실함수, metric 설정\n",
        "#학습시작\n",
        "nb_epoch = 100\n",
        "batch_size = 50\n",
        "autoencoder.compile(optimizer='adam', \n",
        "                    loss='mean_squared_error', \n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "history = autoencoder.fit(x_train, x_train,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(x_test, x_test),\n",
        "                    verbose=1,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PanCMwT_xucR"
      },
      "source": [
        "#2 stage lgbm 학습, 테스트 데이터 생성\n",
        "#lgbm의 경우 따로 인코딩 없이 전체데이터로 학습 및 테스트\n",
        "df_all_lgbm = copy.deepcopy(df_all)\n",
        "\n",
        "del df_all_lgbm['핵심적발']\n",
        "\n",
        "df_train_lgbm, df_test_lgbm = train_test_split(df_all_lgbm,test_size=0.2,random_state=13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXAGzSm7HrVw"
      },
      "source": [
        "#parameter 설정\n",
        "\n",
        "parms = {\n",
        "    'learning_rate' : 0.05,\n",
        "    'n_estimators' : 500,\n",
        "    'num_iterations' : 500,\n",
        "    'max_depth' : -1,\n",
        "    'n_jobs': -1,\n",
        "    'scale_pos_weight' : 1.3,\n",
        "    'early_stopping_rounds':30,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp_Y7x0aHwBH"
      },
      "source": [
        "#lgbm 모델 학습\n",
        "lgbm_model_save = []\n",
        "\n",
        "folds = KFold(n_splits=5, shuffle=True, random_state=1325)\n",
        "\n",
        "for train_idx, valid_idx in folds.split(df_train_lgbm):\n",
        "\n",
        "  lgbm = LGBMClassifier(**parms,random_state=1325)\n",
        "  \n",
        "  train_x, train_y = df_train_lgbm.iloc[train_idx,0:-1],df_train_lgbm.iloc[train_idx,-1]\n",
        "  valid_x, valid_y = df_train_lgbm.iloc[valid_idx,0:-1],df_train_lgbm.iloc[valid_idx,-1]\n",
        "\n",
        "  lgbm.fit(train_x,train_y,early_stopping_rounds=30,eval_set=[(valid_x,valid_y)],verbose=100) \n",
        "\n",
        "  lgbm_model_save.append(lgbm)\n",
        "\n",
        "  print('==============')\n",
        "\n",
        "  y_val = df_test_lgbm.iloc[:,-1]\n",
        "  pred_val = lgbm.predict(df_test_lgbm.iloc[:,:-1])\n",
        "\n",
        "  print('accuracy', metrics.accuracy_score(y_val,pred_val) )\n",
        "  print('precision', metrics.precision_score(y_val,pred_val) )\n",
        "  print('recall', metrics.recall_score(y_val,pred_val) )\n",
        "  print('f1', metrics.f1_score(y_val,pred_val) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o57t-jgx0oP0"
      },
      "source": [
        "#soft voting 구현\n",
        "\n",
        "temp = np.zeros((df_test_lgbm.shape[0],2))\n",
        "\n",
        "for m in lgbm_model_save:\n",
        "  predict_proba =  m.predict_proba(df_test_lgbm.iloc[:,:-1])\n",
        "  temp += predict_proba/5\n",
        "  \n",
        "result = []\n",
        "\n",
        "for i in temp:\n",
        "  if i[0] > i[1]:\n",
        "    result.append(0)\n",
        "  else:\n",
        "    result.append(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa6LhkePK8aS"
      },
      "source": [
        "#submission 위한 코드\n",
        "#df_all 변수에 데이터 넣어주고 사용해야함\n",
        "#코드 실행전 #데이터 전처리# 적혀있는 코드 실행해줘야함 \n",
        "\n",
        "#1 stage\n",
        "\n",
        "first_result = ce_model.transform(df_all)\n",
        "\n",
        "auto_result = autoencoder.predict(first_result)\n",
        "\n",
        "x_value = first_result.values\n",
        "\n",
        "temp = []\n",
        "\n",
        "for i in range(0,len(first_result)):\n",
        "  temp.append(metrics.mean_squared_error(x_value[i], auto_result[i]))``\n",
        "\n",
        "first_result['이상치'] = temp\n",
        "first_result['이상치'] = first_result['이상치']*100000000\n",
        "first_result = first_result[first_result['이상치']>300]\n",
        "\n",
        "del first_result['이상치']\n",
        "first_result['우범'] = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgB0Nsh8S9sB"
      },
      "source": [
        "# 2-stage lgbm, soft voting 사용하여 temp 변수에 정상, 우범 예측 확률 저장\n",
        "\n",
        "temp = np.zeros((df_all.shape[0],2))\n",
        "\n",
        "for m in lgbm_model_save:\n",
        "  predict_proba =  m.predict_proba(df_all)\n",
        "  temp += predict_proba/5\n",
        "\n",
        "### probability 조정 ###\n",
        "\n",
        "# 1-stage 핵심 우범으로 분류 된 데이터 한정으로 LGBM 정상 확률 0.8 이상이면 정상으로 변경\n",
        "\n",
        "result = []\n",
        "\n",
        "for val in temp[first_result.index]:\n",
        "\n",
        "  if val[0] > 0.8 :\n",
        "    result.append(0)\n",
        "  else :\n",
        "    result.append(1)\n",
        "\n",
        "first_result['우범'] = result\n",
        "\n",
        "# 2-stage 우범 확률 0.4 이상 우범으로 판정\n",
        "\n",
        "result_2 = []\n",
        "\n",
        "for val in temp:\n",
        "\n",
        "  if val[1] > 0.4 :\n",
        "    result_2.append(1)\n",
        "  else :\n",
        "    result_2.append(0)\n",
        "\n",
        "# 1-stage 2-stage 결과 합치기\n",
        "\n",
        "df_all['우범'] = result_2\n",
        "\n",
        "df_all['우범'][first_result[first_result['우범'] == 0].index] = 0\n",
        "df_all['우범'][first_result[first_result['우범'] == 1].index] = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}